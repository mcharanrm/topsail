{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential modules/packages that are required\n",
    "# for the work of Regressional Analysis\n",
    "\n",
    "import json\n",
    "import pandas\n",
    "import requests\n",
    "import statistics\n",
    "\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf631a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run few preflight checks to make sure\n",
    "# the notebook has all the required information \n",
    "# to execute the cells without any exceptions.\n",
    "\n",
    "# The SECRETS_FILE is a JSON_FILE that contains \n",
    "# the details of OPENSEARCH_HOST_ADDRESS, USER_NAME, and PASSWORD \n",
    "SECRETS_FILE = ''\n",
    "\n",
    "assert SECRETS_FILE, \"variable `SECRETS_FILE` is Null/None. Provide absolute path to your JSON file\"\n",
    "\n",
    "with open(SECRETS_FILE, 'r') as file_data:\n",
    "    SECRETS = json.load(file_data)\n",
    "    \n",
    "assert SECRETS['opensearch_cluster'], \"variable `opensearch_cluster` is Null/None\"\n",
    "assert SECRETS['opensearch_user'], \"variable `opensearch_user` is Null/None\"\n",
    "assert SECRETS['opensearch_user_password'], \"variable `opensearch_user_password` is Null/None\"\n",
    "assert SECRETS['ca_cert_file'], \"variable `ca_cert_file` is Null/None. Provide absolute path to `.pem` file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d579c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RHOAI version numbers from the Opensearch cluster.\n",
    "INDEX_FIELD = \"metadata.settings.rhoai_version.keyword\"\n",
    "NUMBER_OF_RECORDS = 100\n",
    "\n",
    "def get_version_numbers_of_rhoai():\n",
    "    '''\n",
    "    Returns the list of RHOAI Versions that \n",
    "    were tested by PSAP team as part of the\n",
    "    release process\n",
    "    '''\n",
    "    \n",
    "    data_aggregation_query = {\n",
    "                              \"aggs\": {\n",
    "                                \"rhoai_versions\": {\n",
    "                                  \"terms\": {\n",
    "                                    \"field\": f\"{INDEX_FIELD}\",\n",
    "                                    \"size\": NUMBER_OF_RECORDS\n",
    "                                  }\n",
    "                                }\n",
    "                              }\n",
    "                            }\n",
    "    \n",
    "    \n",
    "    response = requests.get(\n",
    "        url=SECRETS['opensearch_cluster'] + '/psap-rhoai.rhoai-kserve-single/_search?size=0&_source=false',\n",
    "        auth=(SECRETS['opensearch_user'], SECRETS['opensearch_user_password']),\n",
    "        verify=SECRETS['ca_cert_file'],\n",
    "        json=data_aggregation_query\n",
    "    )\n",
    "    \n",
    "    assert response.status_code == 200, f\"HTTP GET request failed, status code - {response.status_code}, \\\n",
    "error message - {response.json()}\"\n",
    "    \n",
    "    return [ _version['key'] for _version in response.json()['aggregations']['rhoai_versions']['buckets'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the RHOAI versions that are available in Opensearch cluster\n",
    "RHOAI_VERSIONS = sorted(get_version_numbers_of_rhoai(), reverse=True)\n",
    "RHOAI_VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define current, ignored, preferred_released_versions for regression analysis\n",
    "CURRENT_VERSION =                               # string\n",
    "IGNORED_VERSION = []                            # List of strings\n",
    "PREFERRED_RELEASED_VERSIONS = [ _version for _version in RHOAI_VERSIONS \\\n",
    "                               if _version != CURRENT_VERSION and _version not in IGNORED_VERSION\n",
    "                              ]\n",
    "\n",
    "assert CURRENT_VERSION, 'Variable `CURRENT_VERSION` is Null/None.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numbers specific to each KPI\n",
    "\n",
    "def get_llm_load_test_kpi_results(kpi_field):\n",
    "    '''\n",
    "    Returns the results/observations of a specific KPI\n",
    "    '''\n",
    "    \n",
    "    data_aggregation_query = {\n",
    "      \"aggs\": {\n",
    "        \"users\": {\n",
    "          \"terms\": {\n",
    "            \"field\": \"metadata.settings.virtual_users\",\n",
    "            \"size\": 100\n",
    "          },\n",
    "          \"aggs\": {\n",
    "            \"models\": {\n",
    "              \"terms\": {\n",
    "                \"field\": \"metadata.settings.model_name.keyword\",\n",
    "                \"size\": 100\n",
    "              },\n",
    "              \"aggs\": {\n",
    "                \"rhoai\": {\n",
    "                  \"terms\": {\n",
    "                    \"field\": \"metadata.settings.rhoai_version.keyword\",\n",
    "                    \"size\": 100\n",
    "                  },\n",
    "                  \"aggs\": {\n",
    "                    \"stats\": {\n",
    "                      \"extended_stats\": {\n",
    "                        \"field\": f\"{kpi_field}\"\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        url=SECRETS['opensearch_cluster'] + '/psap-rhoai.rhoai-kserve-single/_search?size=0&_source=false',\n",
    "        auth=(SECRETS['opensearch_user'], SECRETS['opensearch_user_password']),\n",
    "        verify=SECRETS['ca_cert_file'],\n",
    "        json=data_aggregation_query\n",
    "    )\n",
    "    \n",
    "    \n",
    "    assert response.status_code == 200, f\"HTTP GET request failed, status code - {response.status_code}, \\\n",
    "error message - {response.json()}\"\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out current version results\n",
    "\n",
    "def get_current_version_results(response):\n",
    "    '''\n",
    "    Only returns results of the current version\n",
    "    '''\n",
    "    \n",
    "    kpi_stats_avg = dict()\n",
    "    for user_concurrency in response['aggregations']['users']['buckets']:\n",
    "        number_of_virtual_users = user_concurrency['key']\n",
    "        kpi_stats_avg[number_of_virtual_users] = dict()\n",
    "\n",
    "        for model in user_concurrency['models']['buckets']:\n",
    "            model_name = model['key']\n",
    "\n",
    "            for rhoai_version in model['rhoai']['buckets']:\n",
    "                rhoai_version_number = rhoai_version['key']\n",
    "\n",
    "                if rhoai_version_number == CURRENT_VERSION:\n",
    "                    avg_value = rhoai_version['stats']['avg']\n",
    "                    # persist the information to a dictionary\n",
    "                    kpi_stats_avg[number_of_virtual_users][model_name] = avg_value\n",
    "                    break\n",
    "\n",
    "    return kpi_stats_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the results of PREFERRED_RELEASED_VERSIONS.\n",
    "\n",
    "def get_preferred_released_version_results(response):\n",
    "    '''\n",
    "    Returns the measurements of the other versions\n",
    "    that are different from the current version\n",
    "    '''\n",
    "    \n",
    "    kpi_stats_avg = dict()\n",
    "\n",
    "    for user_concurrency in response['aggregations']['users']['buckets']:\n",
    "        number_of_virtual_users = user_concurrency['key']\n",
    "        kpi_stats_avg[number_of_virtual_users] = dict()\n",
    "\n",
    "        for model in user_concurrency['models']['buckets']:\n",
    "            model_name = model['key']\n",
    "            kpi_measurements = list()\n",
    "\n",
    "            for rhoai_version in model['rhoai']['buckets']:\n",
    "                rhoai_version_number = rhoai_version['key']\n",
    "\n",
    "                if rhoai_version_number in PREFERRED_RELEASED_VERSIONS:\n",
    "                    avg_value = rhoai_version['stats']['avg']\n",
    "                    kpi_measurements.append(avg_value)\n",
    "        \n",
    "            # persist the information into a dictionary\n",
    "            kpi_stats_avg[number_of_virtual_users][model_name] = kpi_measurements\n",
    "\n",
    "    return kpi_stats_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf35646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data for the `Line Charts`\n",
    "\n",
    "def get_data_for_line_charts(response):\n",
    "    '''\n",
    "    Returns the measurements in a format\n",
    "    that is compatible with Line Charts\n",
    "    '''\n",
    "    \n",
    "    line_chart_data = dict()\n",
    "    \n",
    "    for user_concurrency in response['aggregations']['users']['buckets']:\n",
    "        number_of_virtual_users = user_concurrency['key']\n",
    "        line_chart_data[number_of_virtual_users] = dict()\n",
    "\n",
    "        for model in user_concurrency['models']['buckets']:\n",
    "            model_name = model['key']\n",
    "            line_chart_data[number_of_virtual_users][model_name] = dict()\n",
    "\n",
    "            for rhoai_version in model['rhoai']['buckets']:\n",
    "                rhoai_version_number = rhoai_version['key']\n",
    "\n",
    "                if rhoai_version_number in PREFERRED_RELEASED_VERSIONS or rhoai_version_number == CURRENT_VERSION:\n",
    "                    avg_value = rhoai_version['stats']['avg']\n",
    "                    line_chart_data[number_of_virtual_users][model_name][rhoai_version_number] = avg_value\n",
    "\n",
    "    return line_chart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample/population mean\n",
    "\n",
    "def get_measure_of_center(data):\n",
    "    '''\n",
    "    Returns Mean to determine the limits\n",
    "    '''\n",
    "    \n",
    "    return statistics.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample/population standard deviation\n",
    "\n",
    "def get_measure_of_distribution(data):\n",
    "    '''\n",
    "    Returns STDDEV to determine the limits\n",
    "    '''\n",
    "    \n",
    "    return statistics.stdev(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83417a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_change(mean, previous_data):\n",
    "    '''\n",
    "    Returns %change w.r.t the average mean\n",
    "    '''\n",
    "\n",
    "    previous_data_avg = get_measure_of_center(previous_data)\n",
    "    return (((mean / previous_data_avg) * 100) - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b26124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(mean, previous_data):\n",
    "    '''\n",
    "    Returns the difference of current_mean and previous_mean\n",
    "    '''\n",
    "\n",
    "    previous_data_avg = get_measure_of_center(previous_data)\n",
    "    return (mean - previous_data_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccafc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_dev_measurements(deviation, mean, previous_data):\n",
    "    '''\n",
    "    Returns standard deviation bounds\n",
    "    '''\n",
    "\n",
    "    previous_data_avg = get_measure_of_center(previous_data)\n",
    "    previous_data_stddev = get_measure_of_distribution(previous_data)\n",
    "\n",
    "    if deviation == 1:\n",
    "        std_lower_bound = previous_data_avg - (previous_data_stddev * deviation)\n",
    "        std_upper_bound = previous_data_avg + (previous_data_stddev * deviation)\n",
    "\n",
    "        number_of_observation = [ item for item in previous_data if item <= std_upper_bound and item >= std_lower_bound ]\n",
    "        if mean <= std_upper_bound and mean >= std_lower_bound:\n",
    "            bound_verify = True\n",
    "        else:\n",
    "            bound_verify = False\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "        std_lower_bound_1 = previous_data_avg - (previous_data_stddev * (deviation - 1))\n",
    "        std_lower_bound_2 = previous_data_avg - (previous_data_stddev * deviation)\n",
    "        std_upper_bound_1 = previous_data_avg + (previous_data_stddev * (deviation - 1))\n",
    "        std_upper_bound_2 = previous_data_avg + (previous_data_stddev * deviation)\n",
    "\n",
    "        number_of_observation_below_the_mean = [ item for item in previous_data if item <= std_lower_bound_1 and item >= std_lower_bound_2 ]\n",
    "        number_of_observation_above_the_mean = [item for item in previous_data if item >= std_upper_bound_1 and item <= std_upper_bound_2 ]\n",
    "\n",
    "        number_of_observation = number_of_observation_above_the_mean + number_of_observation_below_the_mean\n",
    "\n",
    "        if mean <= std_lower_bound_1 and mean >= std_lower_bound_2:\n",
    "            bound_verify = True\n",
    "        elif mean >= std_upper_bound_1 and mean <= std_upper_bound_2:\n",
    "            bound_verify = True\n",
    "        else:\n",
    "            bound_verify = False\n",
    "\n",
    "    return ((len(number_of_observation)/len(previous_data)) * 100), bound_verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame_values(current_data, old_data):\n",
    "    '''\n",
    "    Returns data compatible with Pandas DataFrame\n",
    "    '''\n",
    "    \n",
    "    # Lets define schema for the dataFrame\n",
    "    data_frame_for_regressional_analysis = dict()\n",
    "    data_frame_for_regressional_analysis['user_concurrency'] = list()\n",
    "    data_frame_for_regressional_analysis['model_name'] = list()\n",
    "    data_frame_for_regressional_analysis['present_ver_mean'] = list()\n",
    "    data_frame_for_regressional_analysis['previous_ver_mean'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_1'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_1_bound'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_2'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_2_bound'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_3'] = list()\n",
    "    data_frame_for_regressional_analysis['std_dev_3_bound'] = list()\n",
    "    data_frame_for_regressional_analysis['change'] = list()\n",
    "    data_frame_for_regressional_analysis['delta'] = list()\n",
    "    \n",
    "    for user_concurrency, kpi_measurements in current_data.items():\n",
    "        for model_name, mean_value in kpi_measurements.items():\n",
    "            data_frame_for_regressional_analysis['user_concurrency'].append(user_concurrency)\n",
    "            data_frame_for_regressional_analysis['model_name'].append(model_name)\n",
    "            data_frame_for_regressional_analysis['present_ver_mean'].append(mean_value)\n",
    "            data_frame_for_regressional_analysis['previous_ver_mean'].append(get_measure_of_center(old_data[user_concurrency][model_name]))\n",
    "            data_frame_for_regressional_analysis['std_dev'].append(get_measure_of_distribution(old_data[user_concurrency][model_name]))\n",
    "            dist_1, bound_1 = get_std_dev_measurements(1, mean_value, old_data[user_concurrency][model_name])\n",
    "            data_frame_for_regressional_analysis['std_dev_1'].append(dist_1)\n",
    "            data_frame_for_regressional_analysis['std_dev_1_bound'].append(bound_1)\n",
    "            dist_2, bound_2 = get_std_dev_measurements(2, mean_value, old_data[user_concurrency][model_name])\n",
    "            data_frame_for_regressional_analysis['std_dev_2'].append(dist_2)\n",
    "            data_frame_for_regressional_analysis['std_dev_2_bound'].append(bound_2)\n",
    "            dist_3, bound_3 = get_std_dev_measurements(3, mean_value, old_data[user_concurrency][model_name])\n",
    "            data_frame_for_regressional_analysis['std_dev_3'].append(dist_3)\n",
    "            data_frame_for_regressional_analysis['std_dev_3_bound'].append(bound_3)\n",
    "            data_frame_for_regressional_analysis['change'].append(get_percentage_change(mean_value, old_data[user_concurrency][model_name]))\n",
    "            data_frame_for_regressional_analysis['delta'].append(get_delta(mean_value, old_data[user_concurrency][model_name]))\n",
    "            \n",
    "    return data_frame_for_regressional_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_property(cellData):\n",
    "    '''\n",
    "    Returns the color property for the Table rows\n",
    "    '''    \n",
    "    bool_val = cellData.std_dev_1_bound or cellData.std_dev_2_bound or cellData.std_dev_3_bound\n",
    "    \n",
    "    if bool_val:\n",
    "        return ['color: black'] * len(cellData.to_dict())\n",
    "    else:\n",
    "        return ['background-color: pink'] * len(cellData.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866de630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare KPIs(Key Performance Indicators).\n",
    "# The KPIs declared here are actually the keys \n",
    "# that are created by the llm-load-test.\n",
    "\n",
    "KPIS = {\n",
    "    'throughput': {\n",
    "        \"field\": \"kpis.kserve_llm_load_test_throughput.value\",\n",
    "        \"help\": \"Model throughput\",\n",
    "        \"unit\": \"(tokens/s)\"\n",
    "    },\n",
    "    'itl': {\n",
    "        \"field\": \"kpis.kserve_llm_load_test_itl.value\",\n",
    "        \"help\": \"All values of inter token latency\",\n",
    "        \"unit\": \"(ms)\"\n",
    "    },\n",
    "    'ttft': {\n",
    "        \"field\": \"kpis.kserve_llm_load_test_ttft.value\",\n",
    "        \"help\": \"All values of time to first token\",\n",
    "        \"unit\": \"[ms]\"\n",
    "    },\n",
    "    'tpot': {\n",
    "        \"field\": \"kpis.kserve_llm_load_test_tpot.value\",\n",
    "        \"help\": \"All values of time per output token\",\n",
    "        \"unit\": \"[ms/token]\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5143aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare properties to style the Table\n",
    "STYLE_TABLE = [\n",
    "            {\n",
    "                'selector': 'tr:hover',\n",
    "                'props': [\n",
    "                    ('background-color', 'yellow'),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'selector': 'th',\n",
    "                'props': [\n",
    "                    ('background-color', 'grey'),\n",
    "                    ('border', '1px solid black'),\n",
    "                    ('border-collapse', 'collapse')\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'selector': 'td',\n",
    "                'props': [\n",
    "                    ('border', '1px solid black'),\n",
    "                    ('border-collapse', 'collapse')\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'selector': 'caption',\n",
    "                'props': [\n",
    "                    ('font-size', '1.875em'),\n",
    "                    ('text-align', 'center')\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "STYLE_FORMAT = {\n",
    "            \"present_ver_mean\": \"{:.1f}\",\n",
    "            \"previous_ver_mean\": \"{:.1f}\",\n",
    "            \"std_dev\": \"{:.1f}\",\n",
    "            \"std_dev_1\": \"{:.1f} %\",\n",
    "            \"std_dev_2\": \"{:.1f} %\",\n",
    "            \"std_dev_3\": \"{:.1f} %\",\n",
    "            \"change\": \"{:.1f} %\",\n",
    "            \"delta\": \"{:.1f}\"\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that calls all other important functions and \n",
    "# returns data that is just compatible enough to provide Table and Line Charts.\n",
    "\n",
    "def get_kpi_data_frame_values(kpi_field):\n",
    "    aggregated_results = get_llm_load_test_kpi_results(kpi_field)\n",
    "    current_version_results = get_current_version_results(aggregated_results)\n",
    "    previous_version_results = get_preferred_released_version_results(aggregated_results)\n",
    "    dataFrame = get_data_frame_values(current_version_results, previous_version_results)\n",
    "    \n",
    "    return aggregated_results, dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughput\n",
    "aggregated_results, kpi_data_frame = get_kpi_data_frame_values(KPIS['throughput']['field'])\n",
    "\n",
    "# A summary of test results that is compared with other versions displayed in a Line Chart\n",
    "VIRTUAL_USERS_CONCURRENCY = 32\n",
    "line_chart_data = get_data_for_line_charts(aggregated_results)\n",
    "line_chart_df = pandas.DataFrame.from_dict(line_chart_data[VIRTUAL_USERS_CONCURRENCY])\n",
    "fig = px.line(\n",
    "    line_chart_df, \n",
    "    markers=True,\n",
    "    title=KPIS['throughput']['help'] + \\\n",
    "        f\" at {VIRTUAL_USERS_CONCURRENCY} concurrency - \" + \\\n",
    "        KPIS['throughput']['unit'],\n",
    "    labels={\n",
    "        \"index\": \"Version(s) of RHOAI\",\n",
    "        \"value\": f\"{KPIS['throughput']['unit']}\"\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Summary of Regression Analysis displayed in Table Chart\n",
    "dataFrame = pandas.DataFrame.from_dict(data=kpi_data_frame)    \n",
    "dataFrame.style.hide_index()\\\n",
    "    .apply(get_color_property, axis=1)\\\n",
    "    .set_table_styles(table_styles=STYLE_TABLE)\\\n",
    "    .format(STYLE_FORMAT)\\\n",
    "    .set_caption(f\"{KPIS['throughput']['help'] + ' ' + KPIS['throughput']['unit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter Token Latency (ITL)\n",
    "aggregated_results, kpi_data_frame = get_kpi_data_frame_values(KPIS['itl']['field'])\n",
    "\n",
    "# A summary of test results that is compared with other versions and displayed in a Line Chart\n",
    "VIRTUAL_USERS_CONCURRENCY = 32\n",
    "line_chart_data = get_data_for_line_charts(aggregated_results)\n",
    "line_chart_df = pandas.DataFrame.from_dict(line_chart_data[VIRTUAL_USERS_CONCURRENCY])\n",
    "fig = px.line(\n",
    "    line_chart_df, \n",
    "    markers=True,\n",
    "    title=KPIS['itl']['help'] + \\\n",
    "        f\" at {VIRTUAL_USERS_CONCURRENCY} concurrency - \" + \\\n",
    "        KPIS['itl']['unit'],\n",
    "    labels={\n",
    "        \"index\": \"Version(s) of RHOAI\",\n",
    "        \"value\": f\"{KPIS['itl']['unit']}\"\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Summary of Regression Analysis displayed in Table Chart\n",
    "dataFrame = pandas.DataFrame.from_dict(data=kpi_data_frame)    \n",
    "dataFrame.style.hide_index()\\\n",
    "    .apply(get_color_property, axis=1)\\\n",
    "    .set_table_styles(table_styles=STYLE_TABLE)\\\n",
    "    .format(STYLE_FORMAT)\\\n",
    "    .set_caption(f\"{KPIS['itl']['help'] + ' ' + KPIS['itl']['unit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ceb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to First Token (TTFT)\n",
    "aggregated_results, kpi_data_frame = get_kpi_data_frame_values(KPIS['ttft']['field'])\n",
    "\n",
    "# A summary of test results that is compared with other versions and displayed in a Line Chart\n",
    "VIRTUAL_USERS_CONCURRENCY = 32\n",
    "line_chart_data = get_data_for_line_charts(aggregated_results)\n",
    "line_chart_df = pandas.DataFrame.from_dict(line_chart_data[VIRTUAL_USERS_CONCURRENCY])\n",
    "fig = px.line(\n",
    "    line_chart_df,\n",
    "    markers=True,\n",
    "    title=KPIS['ttft']['help'] + \\\n",
    "        f\" at {VIRTUAL_USERS_CONCURRENCY} concurrency - \" + \\\n",
    "        KPIS['ttft']['unit'],\n",
    "    labels={\n",
    "        \"index\": \"Version(s) of RHOAI\",\n",
    "        \"value\": f\"{KPIS['ttft']['unit']}\"\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Summary of Regression Analysis displayed in Table Chart\n",
    "dataFrame = pandas.DataFrame.from_dict(data=kpi_data_frame)    \n",
    "dataFrame.style.hide_index()\\\n",
    "    .apply(get_color_property, axis=1)\\\n",
    "    .set_table_styles(table_styles=STYLE_TABLE)\\\n",
    "    .format(STYLE_FORMAT)\\\n",
    "    .set_caption(f\"{KPIS['ttft']['help'] + ' ' + KPIS['ttft']['unit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfefcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time per Output Token\n",
    "aggregated_results, kpi_data_frame = get_kpi_data_frame_values(KPIS['tpot']['field'])\n",
    "\n",
    "# A summary of test results that is compared with other versions and displayed in a Line Chart\n",
    "VIRTUAL_USERS_CONCURRENCY = 32\n",
    "line_chart_data = get_data_for_line_charts(aggregated_results)\n",
    "line_chart_df = pandas.DataFrame.from_dict(line_chart_data[VIRTUAL_USERS_CONCURRENCY])\n",
    "fig = px.line(\n",
    "    line_chart_df,\n",
    "    markers=True,\n",
    "    title=KPIS['tpot']['help'] + \\\n",
    "        f\" at {VIRTUAL_USERS_CONCURRENCY} concurrency - \" + \\\n",
    "        KPIS['tpot']['unit'],\n",
    "    labels={\n",
    "        \"index\": \"Version(s) of RHOAI\",\n",
    "        \"value\": f\"{KPIS['tpot']['unit']}\"\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Summary of Regression Analysis displayed in Table Chart\n",
    "dataFrame = pandas.DataFrame.from_dict(data=kpi_data_frame)    \n",
    "dataFrame.style.hide_index()\\\n",
    "    .apply(get_color_property, axis=1)\\\n",
    "    .set_table_styles(table_styles=STYLE_TABLE)\\\n",
    "    .format(STYLE_FORMAT)\\\n",
    "    .set_caption(f\"{KPIS['tpot']['help'] + ' ' + KPIS['tpot']['unit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea69fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
